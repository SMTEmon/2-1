
The primary method for solving a system of linear equations $A\mathbf{x} = \mathbf{b}$ is **Elimination** (Gaussian Elimination). The entire process can be expressed using matrix multiplication.

https://www.youtube.com/watch?v=QVKj3LADCnA&list=PLE7DDD91010BC51F8&index=4

---

### I. Gaussian Elimination (Forward Elimination)

The goal of elimination is to transform the original matrix $\mathbf{A}$ into an **Upper Triangular Matrix** $\mathbf{U}$ by creating zeros below the main diagonal.

1. **The Pivot:** The first non-zero entry used to perform elimination is the **pivot** ($A_{11}$, $A_{22}$, etc.). **Pivots cannot be zero**.
    
2. **The Multiplier ($l_{i1}$):** This is the ratio used to eliminate an entry. $l_{i1} = \frac{\text{Entry to be eliminated}}{\text{Pivot}}$.
    
3. **The Step:** Subtract $l_{i1} \times (\text{Row 1})$ from $(\text{Row } i)$.
    

The overall transformation (using the augmented matrix) is:

$$\begin{pmatrix} \mathbf{A} & \mathbf{b} \end{pmatrix} \xrightarrow{\text{Elimination}} \begin{pmatrix} \mathbf{U} & \mathbf{c} \end{pmatrix}$$

- $\mathbf{U}$ is the resulting **upper triangular matrix**.
    
- The diagonal entries of $\mathbf{U}$ are the final set of **pivots**.
    

---

### II. Back Substitution

After transforming the system to $\mathbf{U}\mathbf{x} = \mathbf{c}$, the unknowns are solved in reverse order (starting from the last equation) to find the solution vector $\mathbf{x}$.

$$\begin{cases} U_{11}x + U_{12}y + U_{13}z = c_1 \\ \quad \qquad U_{22}y + U_{23}z = c_2 \\ \quad \qquad \quad \qquad U_{33}z = c_3 \end{cases} \implies \text{Solve for } z, \text{ then } y, \text{ then } x.$$

---

### III. Elimination Matrices (Elementary Matrices)

Each step of elimination can be represented by multiplying the matrix $\mathbf{A}$ on the **left** by an **elimination matrix** $\mathbf{E}$.

- Example: Elimination Matrix $\mathbf{E}_{21}$
    
    To subtract $3 \times (\text{Row 1})$ from $(\text{Row 2})$, the matrix $\mathbf{E}_{21}$ is:
    
    $$\mathbf{E}_{21} = \begin{pmatrix} 1 & 0 & 0 \\ -3 & 1 & 0 \\ 0 & 0 & 1 \end{pmatrix}$$
    
- Total Elimination Process
    
    The entire forward elimination process is a sequence of matrix multiplications:
    
    $$\mathbf{E}_{32}(\mathbf{E}_{21}\mathbf{A}) = \mathbf{U}$$
    

---

### IV. Laws of Matrix Multiplication

- Associative Law (True):
    
    $$\mathbf{A}(\mathbf{B}\mathbf{C}) = (\mathbf{A}\mathbf{B})\mathbf{C}$$
    
- Commutative Law (False): The order of matrices cannot be swapped.
    
    $$\mathbf{A}\mathbf{B} \neq \mathbf{B}\mathbf{A}$$
    

---

### V. Matrix Failure and Inverses

#### 1. Failure of Elimination

Elimination **fails** if a pivot is zero.

- **Temporary Failure:** If a zero appears in a pivot position, but a non-zero entry exists below it, the failure is fixed by a **row exchange** (using a **Permutation Matrix** $\mathbf{P}$).
    
- **Complete Failure:** If a zero appears in a pivot position _and_ all entries below it are also zero, the matrix is **singular** (non-invertible), and elimination halts.
    

#### 2. Inverse Matrices

The **inverse matrix** $\mathbf{E}^{-1}$ undoes the operation of $\mathbf{E}$ ($\mathbf{E}^{-1}\mathbf{E} = \mathbf{I}$, the Identity matrix).

- If $\mathbf{E}$ subtracts $l \times (\text{Row } i)$ from $(\text{Row } j)$, then $\mathbf{E}^{-1}$ **adds** $l \times (\text{Row } i)$ to $(\text{Row } j)$.
    

Example: Inverse of $\mathbf{E}_{21}$

If $\mathbf{E}_{21}$ is the matrix to subtract $3 \times (\text{Row 1})$ from $(\text{Row 2})$:

$$\mathbf{E}_{21} = \begin{pmatrix} 1 & 0 & 0 \\ -3 & 1 & 0 \\ 0 & 0 & 1 \end{pmatrix} \quad \implies \quad \mathbf{E}_{21}^{-1} = \begin{pmatrix} 1 & 0 & 0 \\ 3 & 1 & 0 \\ 0 & 0 & 1 \end{pmatrix}$$