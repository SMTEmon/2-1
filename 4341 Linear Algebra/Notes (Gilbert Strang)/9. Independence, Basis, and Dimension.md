# Linear Algebra Lecture 9: Independence, Basis, and Dimension

**Lecturer:** W. Gilbert Strang
**Source:** MIT 18.06 Linear Algebra
**Related Notes:** [[8. Solving Ax = b]], [[6. Vector Spaces and Subspaces]]

---

## 1. The Fundamental Fact (Pre-requisite)

Before defining independence, we establish a crucial fact about systems of equations where the unknowns outnumber the equations.

> [!important] Theorem
> Suppose $A$ is an $m \times n$ matrix with $m < n$ (more unknowns than equations).
> Then there are **non-zero solutions** to $Ax = 0$.

**Reasoning:**
1. If $n > m$, there must be free variables.
2. The number of pivots cannot exceed $m$ (number of rows).
3. Therefore, at least $n - m$ variables are free.
4. We can assign non-zero values to these free variables to find a non-zero solution.

---

## 2. Linear Independence

We describe independence for a set of vectors (not a matrix, though often visualized through one).

### Definition
Vectors $\vec{x}_1, \vec{x}_2, \dots, \vec{x}_n$ are **Linearly Independent** if no linear combination of them gives the zero vector, *except* for the zero combination.

Mathematically, the equation:
$$c_1\vec{x}_1 + c_2\vec{x}_2 + \dots + c_n\vec{x}_n = \vec{0}$$
is true **only** when $c_1 = 0, c_2 = 0, \dots, c_n = 0$.

### Linear Dependence
Vectors are **Linearly Dependent** if there exists a combination (where not all $c_i$ are zero) that equals the zero vector.

$$c_1\vec{x}_1 + \dots + c_n\vec{x}_n = \vec{0} \quad \text{for some } c_i \neq 0$$

### Visual Examples in $\mathbb{R}^2$

1.  **Dependent:** One vector is a multiple of the other. They lie on the same line.
    *   $\vec{v}$ and $2\vec{v}$.
    *   Combination: $2\vec{v} - 1(2\vec{v}) = 0$.
2.  **Dependent:** Any set containing the Zero Vector.
    *   $\vec{v}_1$ and $\vec{0}$.
    *   Combination: $0\vec{v}_1 + 5\vec{0} = 0$. (The coefficient 5 is non-zero).
3.  **Independent:** Vectors pointing in different directions (not on the same line).
    *   The only way to get zero is to take 0 length of both.
4.  **Dependent (3 vectors in $\mathbb{R}^2$):**
    *   Any 3 vectors in a 2D plane *must* be dependent. You can always express one as a combination of the others.

### Connection to Matrix A
If we place the vectors $\vec{v}_1, \dots, \vec{v}_n$ as the columns of a matrix $A$:

*   **Independence:** The Nullspace $N(A)$ contains **only** the zero vector.
    *   Rank $r = n$ (number of columns).
    *   No free variables.
*   **Dependence:** The Nullspace $N(A)$ contains non-zero vectors.
    *   Rank $r < n$.
    *   There are free variables.

---

## 3. Spanning a Space

### Definition
Vectors $\vec{v}_1, \dots, \vec{v}_l$ **span** a space $S$ if $S$ consists of all possible linear combinations of those vectors.

$$S = \{ c_1\vec{v}_1 + \dots + c_l\vec{v}_l \mid c_i \in \mathbb{R} \}$$

**Note:** The columns of matrix $A$ *span* the Column Space $C(A)$ by definition.

---

## 4. Basis

This is the central concept connecting Independence and Spanning. A basis is "just enough" vectors to describe a spaceâ€”not too few (wouldn't span), not too many (would be dependent).

### Definition
A sequence of vectors $\vec{v}_1, \dots, \vec{v}_d$ is a **Basis** for a space if they satisfy two properties:
1. They are **Linearly Independent**.
2. They **Span** the space.

### Example: $\mathbb{R}^3$

**Basis 1 (Standard Basis):**
$$
\begin{bmatrix} 1 \\ 0 \\ 0 \end{bmatrix}, \begin{bmatrix} 0 \\ 1 \\ 0 \end{bmatrix}, \begin{bmatrix} 0 \\ 0 \\ 1 \end{bmatrix}
$$
*   Independent? Yes.
*   Span $\mathbb{R}^3$? Yes.

**Basis 2 (Invertible Matrix):**
$$
\begin{bmatrix} 1 \\ 1 \\ 2 \end{bmatrix}, \begin{bmatrix} 2 \\ 2 \\ 5 \end{bmatrix}, \begin{bmatrix} 3 \\ 4 \\ 8 \end{bmatrix}
$$
If we put these vectors into a matrix, the matrix is **invertible** (determinant $\neq 0$), so the columns form a basis for $\mathbb{R}^3$.

**Non-Basis Example:**
$$
\begin{bmatrix} 1 \\ 1 \\ 2 \end{bmatrix}, \begin{bmatrix} 2 \\ 2 \\ 5 \end{bmatrix}, \begin{bmatrix} 3 \\ 3 \\ 7 \end{bmatrix}, \begin{bmatrix} 3 \\ 3 \\ 8 \end{bmatrix}
$$
These 4 vectors in $\mathbb{R}^3$ **span** the space, but they are **dependent**. They are too many.

---

## 5. Dimension

Given a specific vector space, there are infinitely many different bases (you can rotate them, stretch them, etc.). However, they all share one property.

> [!important] Theorem
> Every basis for a specific vector space contains the **same number** of vectors.

### Definition
The **Dimension** of a space is the number of vectors in every basis for that space.

### Examples
*   $\dim(\mathbb{R}^n) = n$.
*   $\dim(\text{Point}) = 0$.
*   $\dim(\text{Line}) = 1$.
*   $\dim(\text{Plane}) = 2$.

---

## 6. Subspaces and Dimensions of A

Let $A$ be an $m \times n$ matrix.

### The Column Space $C(A)$
*   The columns **span** $C(A)$.
*   Are they a basis? *Only if they are independent*.
*   **The Pivot Columns form a basis for $C(A)$.**
*   **Dimension of $C(A)$ = Rank $r$.**

### The Nullspace $N(A)$
*   The special solutions (found by setting free variables to 0 or 1 alternatingly) span $N(A)$.
*   They are independent.
*   **The special solutions form a basis for $N(A)$.**
*   **Dimension of $N(A)$ = Number of free variables ($n - r$).**

### Detailed Example
Let matrix $A$ be:
$$
A = \begin{bmatrix} 
1 & 2 & 3 & 1 \\
1 & 1 & 2 & 1 \\
1 & 2 & 3 & 1 
\end{bmatrix}
$$

**1. Find the Rank (Pivot Columns):**
Perform elimination (Row Reduction):
$$
\begin{bmatrix} 
1 & 2 & 3 & 1 \\
0 & -1 & -1 & 0 \\
0 & 0 & 0 & 0 
\end{bmatrix}
$$
*   Pivots are in **Column 1** and **Column 2**.
*   Rank $r = 2$.

**2. Column Space Analysis:**
*   Dimension of $C(A) = r = 2$.
*   Basis for $C(A) = $ The pivot columns of the *original* A:
    $$
    \text{Basis} = \left\{ \begin{bmatrix} 1 \\ 1 \\ 1 \end{bmatrix}, \begin{bmatrix} 2 \\ 1 \\ 2 \end{bmatrix} \right\}
    $$
    *(Note: Column 3 is the sum of Col 1 + Col 2. Col 4 equals Col 1. They are dependent).*

**3. Nullspace Analysis:**
*   Number of columns $n = 4$. Rank $r = 2$.
*   Dimension of $N(A) = n - r = 4 - 2 = 2$.
*   We need 2 independent vectors for the basis. We find the **Special Solutions** via free variables ($x_3, x_4$).
    *   Set $x_3=1, x_4=0 \implies$ solve for pivots $\implies \vec{s}_1 = \begin{bmatrix} -1 \\ -1 \\ 1 \\ 0 \end{bmatrix}$
    *   Set $x_3=0, x_4=1 \implies$ solve for pivots $\implies \vec{s}_2 = \begin{bmatrix} -1 \\ 0 \\ 0 \\ 1 \end{bmatrix}$
*   Basis for $N(A) = \{ \vec{s}_1, \vec{s}_2 \}$.

## Summary Table

| Space | Basis Provided By | Dimension |
| :--- | :--- | :--- |
| **Column Space** $C(A)$ | Pivot Columns of $A$ | $r$ (Rank) |
| **Nullspace** $N(A)$ | Special Solutions | $n - r$ (# Free Vars) |
